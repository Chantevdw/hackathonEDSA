{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import the necessary libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\n\nfrom sklearn.metrics import f1_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-10-11T19:50:05.928968Z","iopub.execute_input":"2021-10-11T19:50:05.929478Z","iopub.status.idle":"2021-10-11T19:50:05.946944Z","shell.execute_reply.started":"2021-10-11T19:50:05.929426Z","shell.execute_reply":"2021-10-11T19:50:05.945833Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## Load in your data from kaggle.  \nBy working in a kaggle kernel, you can access the data directly from the competition, as well as make your submission without downloading your output file","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/edsa-climate-change-belief-analysis-2021/train.csv')\ntest = pd.read_csv('../input/edsa-climate-change-belief-analysis-2021/test.csv')\nsample = pd.read_csv('../input/edsa-climate-change-belief-analysis-2021/sample_submission.csv')\ndf = pd.concat([train, test], axis=0, sort=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:05.948986Z","iopub.execute_input":"2021-10-11T19:50:05.949570Z","iopub.status.idle":"2021-10-11T19:50:06.043194Z","shell.execute_reply.started":"2021-10-11T19:50:05.949516Z","shell.execute_reply":"2021-10-11T19:50:06.042247Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.044300Z","iopub.execute_input":"2021-10-11T19:50:06.044537Z","iopub.status.idle":"2021-10-11T19:50:06.054757Z","shell.execute_reply.started":"2021-10-11T19:50:06.044511Z","shell.execute_reply":"2021-10-11T19:50:06.053741Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.056002Z","iopub.execute_input":"2021-10-11T19:50:06.056224Z","iopub.status.idle":"2021-10-11T19:50:06.073589Z","shell.execute_reply.started":"2021-10-11T19:50:06.056200Z","shell.execute_reply":"2021-10-11T19:50:06.072652Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"sample.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.075598Z","iopub.execute_input":"2021-10-11T19:50:06.075845Z","iopub.status.idle":"2021-10-11T19:50:06.090641Z","shell.execute_reply.started":"2021-10-11T19:50:06.075807Z","shell.execute_reply":"2021-10-11T19:50:06.089379Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train.sentiment.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.091872Z","iopub.execute_input":"2021-10-11T19:50:06.092225Z","iopub.status.idle":"2021-10-11T19:50:06.108715Z","shell.execute_reply.started":"2021-10-11T19:50:06.092184Z","shell.execute_reply":"2021-10-11T19:50:06.107708Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"plot = train['sentiment'].value_counts()\nsns.barplot(plot.index,plot)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.109841Z","iopub.execute_input":"2021-10-11T19:50:06.110091Z","iopub.status.idle":"2021-10-11T19:50:06.334862Z","shell.execute_reply.started":"2021-10-11T19:50:06.110063Z","shell.execute_reply":"2021-10-11T19:50:06.333893Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.336455Z","iopub.execute_input":"2021-10-11T19:50:06.336679Z","iopub.status.idle":"2021-10-11T19:50:06.347675Z","shell.execute_reply.started":"2021-10-11T19:50:06.336653Z","shell.execute_reply":"2021-10-11T19:50:06.346420Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(train.isnull(), yticklabels = False, cbar = False, cmap = \"Blues\")","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.349165Z","iopub.execute_input":"2021-10-11T19:50:06.349490Z","iopub.status.idle":"2021-10-11T19:50:06.556207Z","shell.execute_reply.started":"2021-10-11T19:50:06.349448Z","shell.execute_reply":"2021-10-11T19:50:06.555222Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.559222Z","iopub.execute_input":"2021-10-11T19:50:06.559598Z","iopub.status.idle":"2021-10-11T19:50:06.578446Z","shell.execute_reply.started":"2021-10-11T19:50:06.559554Z","shell.execute_reply":"2021-10-11T19:50:06.577555Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# positive = train[train['label']==0]\n# negative = train[train['label']==1]\n\n# blob = TextBlob(\"This is a train\")\n# blob.tags\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.579746Z","iopub.execute_input":"2021-10-11T19:50:06.580040Z","iopub.status.idle":"2021-10-11T19:50:06.583613Z","shell.execute_reply.started":"2021-10-11T19:50:06.580001Z","shell.execute_reply":"2021-10-11T19:50:06.582813Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## Cleaning Data","metadata":{}},{"cell_type":"code","source":"# #Creating new dataframe and new features\n# df = pd.DataFrame()\n# tw_list[“text”] = tw_list[0]\n# #Removing RT, Punctuation etc\n# remove_rt = lambda x: re.sub(‘RT @\\w+: ‘,” “,x)\n# rt = lambda x: re.sub(“(@[A-Za-z0–9]+)|([⁰-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)”,” “,x)\n# tw_list[“text”] = tw_list.text.map(remove_rt).map(rt)\n# tw_list[“text”] = tw_list.text.str.lower()\n# tw_list.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.584849Z","iopub.execute_input":"2021-10-11T19:50:06.585576Z","iopub.status.idle":"2021-10-11T19:50:06.596749Z","shell.execute_reply.started":"2021-10-11T19:50:06.585533Z","shell.execute_reply":"2021-10-11T19:50:06.595981Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def gen_freq(message):\n    #Will store the list of words\n    word_list = []\n\n    #Loop over all the tweets and extract words into word_list\n    for tw_words in message.split():\n        word_list.extend(tw_words)\n\n    #Create word frequencies using word_list\n    word_freq = pd.Series(word_list).value_counts()\n\n    #Print top 20 words\n    word_freq[:20]\n    \n    return word_freq\n\ngen_freq(train.message.str)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.598237Z","iopub.execute_input":"2021-10-11T19:50:06.599258Z","iopub.status.idle":"2021-10-11T19:50:06.779346Z","shell.execute_reply.started":"2021-10-11T19:50:06.599216Z","shell.execute_reply":"2021-10-11T19:50:06.778465Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#Generate word cloud\nwc = WordCloud(width=400, height=330, max_words=100, background_color='white').generate_from_frequencies(gen_freq(train.message.str))\n\nplt.figure(figsize=(12, 8))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:06.780678Z","iopub.execute_input":"2021-10-11T19:50:06.780892Z","iopub.status.idle":"2021-10-11T19:50:07.547930Z","shell.execute_reply.started":"2021-10-11T19:50:06.780867Z","shell.execute_reply":"2021-10-11T19:50:07.547288Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    #Remove RT\n    message = re.sub(r'RT', '', text)\n    \n    #Fix &\n    message = re.sub(r'&amp;', '&', text)\n    \n    #Remove punctuations\n    message = re.sub(r'[?!.;:,#@-]', '', text)\n\n    #Convert to lowercase to maintain consistency\n#     text = text.lower()\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:07.549025Z","iopub.execute_input":"2021-10-11T19:50:07.549479Z","iopub.status.idle":"2021-10-11T19:50:07.555799Z","shell.execute_reply.started":"2021-10-11T19:50:07.549449Z","shell.execute_reply":"2021-10-11T19:50:07.554952Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from wordcloud import STOPWORDS\n\ntext = train.message.apply(lambda message: clean_text(message))\nword_freq = gen_freq(train.message.str)*100\nword_freq = word_freq.drop(labels=STOPWORDS, errors='ignore')\n\n#Generate word cloud\nwc = WordCloud(width=450, height=330, max_words=200, background_color='white').generate_from_frequencies(word_freq)\n\nplt.figure(figsize=(12, 14))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:07.556862Z","iopub.execute_input":"2021-10-11T19:50:07.557058Z","iopub.status.idle":"2021-10-11T19:50:08.749755Z","shell.execute_reply.started":"2021-10-11T19:50:07.557035Z","shell.execute_reply":"2021-10-11T19:50:08.748952Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    # Tokenise words while ignoring punctuation\n    tokeniser = RegexpTokenizer(r'\\w+')\n    tokens = tokeniser.tokenize(text)\n    \n    # Lowercase and lemmatise \n    lemmatiser = WordNetLemmatizer()\n    lemmas = [lemmatiser.lemmatize(token.lower(), pos='v') for token in tokens]\n    \n    # Remove stopwords\n    keywords= [lemma for lemma in lemmas if lemma not in stopwords.words('english')]\n    return keywords","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:08.750980Z","iopub.execute_input":"2021-10-11T19:50:08.751376Z","iopub.status.idle":"2021-10-11T19:50:08.756932Z","shell.execute_reply.started":"2021-10-11T19:50:08.751346Z","shell.execute_reply":"2021-10-11T19:50:08.756243Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting out the X variable from the target","metadata":{}},{"cell_type":"code","source":"y = train['sentiment']\nX = train['message']","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:08.758014Z","iopub.execute_input":"2021-10-11T19:50:08.758872Z","iopub.status.idle":"2021-10-11T19:50:08.775055Z","shell.execute_reply.started":"2021-10-11T19:50:08.758835Z","shell.execute_reply":"2021-10-11T19:50:08.774115Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## Turning text into something your model can read","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, stop_words=\"english\")\nX_vectorized = vectorizer.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:08.776158Z","iopub.execute_input":"2021-10-11T19:50:08.776422Z","iopub.status.idle":"2021-10-11T19:50:09.522324Z","shell.execute_reply.started":"2021-10-11T19:50:08.776393Z","shell.execute_reply":"2021-10-11T19:50:09.521278Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# # Create an instance of TfidfVectorizer\n# vectoriser = TfidfVectorizer(analyzer=preprocess_text)\n# # Fit to the data and transform to feature matrix\n# X_train = vectoriser.fit_transform(X_train['speech'])\n# # Convert sparse matrix to dataframe\n# X_train = pd.DataFrame.sparse.from_spmatrix(X_train)\n# # Save mapping on which index refers to which words\n# col_map = {v:k for k, v in vectoriser.vocabulary_.items()}\n# # Rename each column using the mapping\n# for col in X_train.columns:\n#     X_train.rename(columns={col: col_map[col]}, inplace=True)\n# X_train","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:09.523399Z","iopub.execute_input":"2021-10-11T19:50:09.523614Z","iopub.status.idle":"2021-10-11T19:50:09.527684Z","shell.execute_reply.started":"2021-10-11T19:50:09.523588Z","shell.execute_reply":"2021-10-11T19:50:09.526735Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# vectorizer = CountVectorizer()\n# X = vectorizer.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:09.528822Z","iopub.execute_input":"2021-10-11T19:50:09.529158Z","iopub.status.idle":"2021-10-11T19:50:09.546131Z","shell.execute_reply.started":"2021-10-11T19:50:09.529130Z","shell.execute_reply":"2021-10-11T19:50:09.545020Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the training data into a training and validation set","metadata":{}},{"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.2,shuffle=True, stratify=y, random_state=11)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:09.549292Z","iopub.execute_input":"2021-10-11T19:50:09.550217Z","iopub.status.idle":"2021-10-11T19:50:09.574871Z","shell.execute_reply.started":"2021-10-11T19:50:09.550175Z","shell.execute_reply":"2021-10-11T19:50:09.573873Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"## Training the model and evaluating using the validation set ","metadata":{}},{"cell_type":"code","source":"rfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\nrfc_pred = rfc.predict(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:09.576021Z","iopub.execute_input":"2021-10-11T19:50:09.576347Z","iopub.status.idle":"2021-10-11T19:50:37.735147Z","shell.execute_reply.started":"2021-10-11T19:50:09.576291Z","shell.execute_reply":"2021-10-11T19:50:37.734377Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"## Checking the performance of our model on the validation set","metadata":{}},{"cell_type":"code","source":"f1_score(y_val, rfc_pred, average=\"macro\")","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:37.736348Z","iopub.execute_input":"2021-10-11T19:50:37.736559Z","iopub.status.idle":"2021-10-11T19:50:37.745109Z","shell.execute_reply.started":"2021-10-11T19:50:37.736533Z","shell.execute_reply":"2021-10-11T19:50:37.744263Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"## Getting our test set ready ","metadata":{}},{"cell_type":"code","source":"testx = test['message']\ntest_vect = vectorizer.transform(testx)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:37.746457Z","iopub.execute_input":"2021-10-11T19:50:37.746781Z","iopub.status.idle":"2021-10-11T19:50:38.072010Z","shell.execute_reply.started":"2021-10-11T19:50:37.746751Z","shell.execute_reply":"2021-10-11T19:50:38.071191Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"## Making predictions on the test set and adding a sentiment column to our original test df","metadata":{}},{"cell_type":"code","source":"y_pred = rfc.predict(test_vect)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:38.073081Z","iopub.execute_input":"2021-10-11T19:50:38.073331Z","iopub.status.idle":"2021-10-11T19:50:38.900258Z","shell.execute_reply.started":"2021-10-11T19:50:38.073290Z","shell.execute_reply":"2021-10-11T19:50:38.899370Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"test['sentiment'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:38.901429Z","iopub.execute_input":"2021-10-11T19:50:38.902093Z","iopub.status.idle":"2021-10-11T19:50:38.907128Z","shell.execute_reply.started":"2021-10-11T19:50:38.902036Z","shell.execute_reply":"2021-10-11T19:50:38.906419Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:38.908162Z","iopub.execute_input":"2021-10-11T19:50:38.908740Z","iopub.status.idle":"2021-10-11T19:50:38.928439Z","shell.execute_reply.started":"2021-10-11T19:50:38.908707Z","shell.execute_reply":"2021-10-11T19:50:38.927368Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"## Creating an output csv for submission","metadata":{}},{"cell_type":"code","source":"test[['tweetid','sentiment']].to_csv('testsubmission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T19:50:38.929799Z","iopub.execute_input":"2021-10-11T19:50:38.930049Z","iopub.status.idle":"2021-10-11T19:50:38.957178Z","shell.execute_reply.started":"2021-10-11T19:50:38.930020Z","shell.execute_reply":"2021-10-11T19:50:38.955888Z"},"trusted":true},"execution_count":62,"outputs":[]}]}